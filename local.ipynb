{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"local.ipynb","provenance":[],"authorship_tag":"ABX9TyOMvwBnXR2NVUhlA9n8bUwo"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"leFZowoDlhw_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"23f47486-6c66-47dc-d210-a96fc146dfc6","executionInfo":{"status":"ok","timestamp":1588124895067,"user_tz":-540,"elapsed":5625,"user":{"displayName":"염기웅","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjX7VJGycIiSE_ScyzrUP21BjN23qYkmpaLsooQow=s64","userId":"17474065399754057575"}}},"source":["from jupyter_main import main"],"execution_count":1,"outputs":[{"output_type":"stream","text":["C:\\Users\\hwnau\\AppData\\Roaming\\Python\\Python36\\site-packages\\mxnet\\optimizer\\optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n","  Optimizer.opt_registry[name].__name__))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"sb2YOb24lq7e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":786},"outputId":"717bad04-539b-401e-bfc0-7f11d4352781","executionInfo":{"status":"error","timestamp":1588124963209,"user_tz":-540,"elapsed":73749,"user":{"displayName":"염기웅","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjX7VJGycIiSE_ScyzrUP21BjN23qYkmpaLsooQow=s64","userId":"17474065399754057575"}}},"source":["main(load_path = \"./checkpoint/KoGPT2_checkpoint_60000.tar\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["using cached model\n","using cached model\n","count check :  ['2', '60000']\n","using cached model\n","(89386,)\n","using cached model\n","KoGPT-2 Transfer Learning Start\n","epoch no.0 train no.60000  loss = 2.86635 avg_loss = 2.86635\n","to_tokens: ['▁[', '이란', '▁수', '▁좀', '▁나', '▁곁에', '에만', '▁있어', '줘', '요', '▁[', '할', '▁때는', '▁그저', '▁내', '▁곁', '에만', '▁있어', '줘', '요', '▁사랑', '|', 'en', 'do', 'f', 'text', '|', '>', '▁[', 'V', 'nt', 'ro', ']', '▁Y', 'ea', 'h', ',', '▁y', 'ea', 'h', ',', '▁y', 'ea', 'h', ',', '▁y', 'ea', 'h', ',', '▁y', 'ea', 'h', ',', 'V', 'er', 'se', '▁1', ']', '▁Y', 'oo', \"'\", '▁w', 't', 'ta', '?', 'ke', '▁this', '▁w', 'hat', '▁you', '▁go', 't', '▁me', '▁li', '▁W', 'hat', '▁you', '▁go', 't', '▁me', '▁li', 'ke', ',', '▁w', 'hat', '▁you', '▁go', 't', '▁me', '?', '▁W', 'V', 'er', 'se', '▁2', ']', '▁W', 'ey', ',', '▁w', 'ab', 'y', ',']\n","사랑할 땐 그저 내 곁에만 있어줘요 사랑할 땐 그저 내 곁에만 있어줘요 <|endoftext|> [Intro] Yeah, yeah, yeah, yeah, yeah [Verse 1] What you got me like, what you got me? What you got me like, what you got me? [Verse 2] Hey, boy,\n","\n","epoch no.0 train no.60010  loss = 2.78870 avg_loss = 2.76920\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m<ipython-input-2-7475633db4f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./checkpoint/KoGPT2_checkpoint_60000.tar\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mC:\\github\\KoGPT2-FineTuning\\jupyter_main.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(epoch, save_path, load_path, data_file_path, batch_size)\u001b[0m\n\u001b[0;32m    132\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m                         \u001b[0mavg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.99\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.99\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 232.00 MiB (GPU 0; 8.00 GiB total capacity; 5.50 GiB already allocated; 105.10 MiB free; 6.16 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"r6qs-tP_lrcp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}